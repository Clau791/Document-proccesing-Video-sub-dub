@app.route('/api/redub-video', methods=['POST'])
def redub_video():
    """III.2: Redublare Video cu detectare automată a limbii și TTS local (RTX-ready)."""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        voice_sample = request.files.get('voice_sample')  # opțional pentru voice cloning
        dest_lang = request.form.get('dest_lang', 'ro').lower()
        translator_mode = request.form.get('translator_mode', 'cloud').lower()
        detail_level = request.form.get('detail_level', 'medium')
        
        if not validate_file(file, 'redub'):
            return jsonify({'error': 'Invalid file type'}), 400
        
        filename = generate_unique_filename(file.filename)
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        file.save(filepath)

        speaker_wav_path = None
        if voice_sample:
            speaker_name = f"{Path(filename).stem}_voice.wav"
            speaker_wav_path = os.path.join(UPLOAD_FOLDER, speaker_name)
            voice_sample.save(speaker_wav_path)
        
        print(f"\n[REDUB] AUTO → {dest_lang.upper()}: {filename}")
        
        redubber = VideoRedubber()
        result = redubber.redub(filepath, dest_lang=dest_lang, speaker_wav=speaker_wav_path, translator_mode=translator_mode)
        
        response_payload = {
            'service': 'Video Redub',
            'originalFile': filename,
            'originalLanguage': result.get('detected_language', 'auto').upper(),
            'targetLanguage': dest_lang.upper(),
            'downloadUrl': result.get('video_file', ''),
            'subtitleUrl': result.get('subtitle_file', ''),
            'summaryUrl': result.get('summary_file', ''),
            'detailLevel': detail_level,
            'status': 'success',
            **result
        }
        add_history(
            'redub-video',
            filename,
            response_payload.get('downloadUrl'),
            meta={
                'target_lang': dest_lang,
                'translator_mode': translator_mode,
                'detail_level': detail_level,
                'subtitle_url': response_payload.get('subtitleUrl')
            },
            summary_url=response_payload.get('summaryUrl') or result.get('summary_file'),
            summary_text=result.get('summary_text') or ""
        )
        return jsonify(response_payload), 200
        
    except Exception as e:
        print(f"[REDUB] ERROR: {e}")



import os
import shutil
import subprocess
import requests
import re
import wave
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

import torch
import whisper
import ffmpeg
from pydub import AudioSegment
from deep_translator import GoogleTranslator
from num2words import num2words

# === CONFIGURARE GLOBALA ===
OLLAMA_URL = os.getenv("OLLAMA_HOST", "http://localhost:11434")
OLLAMA_MODEL = "qwen2.5:32b"
MAX_WORKERS_TRANSLATION = 8 

# === CONFIGURARE VOCI (Piper) ===
MODELS_DIR = Path("piper_models")
MODELS_DIR.mkdir(exist_ok=True)

# Definim vocile disponibile și URL-urile lor
VOICES_CONFIG = {
    "mihaela": {
        "description": "Feminin, Calmă, Calitate Medie (Standard)",
        "onnx": "https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/ro/ro_RO/mihaela/medium/ro_RO-mihaela-medium.onnx",
        "json": "https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/ro/ro_RO/mihaela/medium/ro_RO-mihaela-medium.onnx.json"
    },
    "doru": {
        "description": "Masculin, Serios, Calitate Medie",
        "onnx": "https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/ro/ro_RO/doru/medium/ro_RO-doru-medium.onnx",
        "json": "https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/ro/ro_RO/doru/medium/ro_RO-doru-medium.onnx.json"
    }
}

# Scriem rezultatele în același director pe care îl servește /download din app.py
PROCESSED_DIR = Path("processed")
PROCESSED_DIR.mkdir(parents=True, exist_ok=True)


class TextNormalizer:
    @staticmethod
    def normalize(text: str) -> str:
        if not text: return ""
        text = text.replace("%", " la sută ").replace("+", " plus ").replace("&", " și ")
        def replace_num(match):
            val = match.group(0).replace(',', '.')
            try:
                if '.' in val: return num2words(float(val), lang='ro')
                return num2words(int(val), lang='ro')
            except: return val
        text = re.sub(r'\d+[.,]?\d*', replace_num, text)
        return " ".join(text.split())

class AudioTools:
    @staticmethod
    def extract_wav(video_path: Path, out_path: Path, sr: int = 22050):
        # Ambele modele (Doru si Mihaela) sunt 'medium' la 22050Hz
        cmd = ["ffmpeg", "-y", "-i", str(video_path), "-vn", "-ac", "1", "-ar", str(sr), "-f", "wav", str(out_path)]
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    @staticmethod
    def high_quality_stretch(input_wav: Path, target_duration_ms: float, output_wav: Path):
        if not input_wav.exists(): return False
        try:
            probe = ffmpeg.probe(str(input_wav))
            duration = float(probe['format']['duration'])
        except: return False

        if duration < 0.1: return False
        ratio = (target_duration_ms / 1000.0) / duration
        
        # Limite de siguranță
        if ratio < 0.85: ratio = 0.85
        if ratio > 1.25: ratio = 1.25
        
        try:
            (
                ffmpeg.input(str(input_wav))
                .filter('atempo', 1.0 / ratio)
                .output(str(output_wav))
                .overwrite_output().run(quiet=True)
            )
            return True
        except Exception: return False

class LLMTranslator:
    def _init_(self):
        self.api_url = f"{OLLAMA_URL}/v1/completions"
        self.google = None  # inițializat lazy cu limba corectă

    def translate_and_adapt(self, text: str, duration: float, dest_lang: str = "ro") -> str:
        try:
            base_ro = GoogleTranslator(source='auto', target=dest_lang).translate(text)
        except: base_ro = text

        if duration < 1.0 and len(base_ro.split()) < 3: return base_ro

        prompt = (
            f"Ești editor dublaj. Timp: {duration:.1f}s. Orig: '{text}'. Draft: '{base_ro}'. "
            f"Rescrie textul în {dest_lang.upper()} să fie NATURAL și SCURT. Returnează DOAR textul."
        )
        try:
            resp = requests.post(self.api_url, json={
                "model": OLLAMA_MODEL, "prompt": prompt, "stream": False, "options": {"temperature": 0.2, "num_ctx": 2048}
            }, timeout=3)
            if resp.ok:
                res = resp.json().get("choices", [{}])[0].get("text", "").strip().replace('"','')
                if len(res) > 1: return res
        except: pass
        return base_ro

class PiperEngine:
    """Motor TTS care suportă schimbarea dinamică a vocii."""
    
    def _init_(self, voice_name: str = "doru"):
        if voice_name not in VOICES_CONFIG:
            print(f"[WARN] Vocea '{voice_name}' nu există. Folosesc 'mihaela'.")
            voice_name = "mihaela"
            
        self.voice_name = voice_name
        self.config = VOICES_CONFIG[voice_name]
        
        self.model_path = MODELS_DIR / f"{voice_name}.onnx"
        self.config_path = MODELS_DIR / f"{voice_name}.onnx.json"
        
        self._ensure_model()
        
        print(f"[TTS] Loading Piper Voice: {voice_name} ({self.config['description']})")
        try:
            import piper
            self.voice = piper.PiperVoice.load(
                str(self.model_path), 
                config_path=str(self.config_path), 
                use_cuda=torch.cuda.is_available()
            )
        except ImportError:
            raise RuntimeError("Rulează: pip install piper-tts")

    def _ensure_model(self):
        """Descarcă fișierele specifice vocii selectate."""
        if not self.model_path.exists():
            print(f"[TTS] Downloading {self.voice_name} model...")
            with open(self.model_path, 'wb') as f:
                f.write(requests.get(self.config['onnx']).content)
                
        if not self.config_path.exists():
            print(f"[TTS] Downloading {self.voice_name} config...")
            with open(self.config_path, 'wb') as f:
                f.write(requests.get(self.config['json']).content)

    def synthesize(self, text: str, out_path: Path):
        if not text: return False
        try:
            with wave.open(str(out_path), "wb") as wav_file:
                self.voice.synthesize(text, wav_file)
            return True
        except Exception as e:
            print(f"[Piper Error] {e}")
            return False

class VideoRedubber:
    def _init_(self):
        print("[INIT] Ready.")
        self.llm = LLMTranslator()

    def run(self, video_path: str, voice: str = "mihaela", dest_lang: str = "ro", translator_mode: str = "cloud"):
        """
        Args:
            video_path: Calea către video.
            voice: 'mihaela' (feminin) sau 'doru' (masculin).
            dest_lang: Limba țintă (default: ro).
            translator_mode: Compatibilitate cu semnătura din app.py (cloud/local).
        """
        video_path = Path(video_path)
        job_id = f"{video_path.stem}_{voice}"
        work_dir = PROCESSED_DIR / job_id
        if work_dir.exists(): shutil.rmtree(work_dir)
        work_dir.mkdir(parents=True, exist_ok=True)

        print(f"\n=== JOB START: {video_path.name} | Voice: {voice.upper()} ===")
        
        # 1. Init TTS cu vocea cerută
        tts_engine = PiperEngine(voice_name=voice)

        # 2. Extract & Transcribe
        full_wav = work_dir / "original.wav"
        AudioTools.extract_wav(video_path, full_wav)
        
        print("[STEP 1] Transcribing...")
        model = whisper.load_model("large-v3", device="cuda" if torch.cuda.is_available() else "cpu")
        res = model.transcribe(str(full_wav), task="transcribe", verbose=False)
        detected_lang = res.get("language", "auto")
        segments = res["segments"]
        del model; torch.cuda.empty_cache()

        # 3. Translate
        print(f"[STEP 2] Translating ({len(segments)} segments)...")
        translated_data = [None] * len(segments)
        
        def process(idx, seg):
            dur = seg['end'] - seg['start']
            txt = seg['text'].strip()
            if not txt or dur < 0.2: return None

            # translator_mode este păstrat pentru compatibilitate; pipeline-ul folosește Google + Ollama fallback
            ro = self.llm.translate_and_adapt(txt, dur, dest_lang=dest_lang)
            return {"idx": idx, "start": seg['start'], "duration": dur, "text": TextNormalizer.normalize(ro)}

        with ThreadPoolExecutor(max_workers=MAX_WORKERS_TRANSLATION) as exc:
            futures = {exc.submit(process, i, s): i for i, s in enumerate(segments)}
            for f in as_completed(futures):
                r = f.result()
                if r: translated_data[r['idx']] = r

        # 4. Synthesize
        print(f"[STEP 3] Synthesizing with voice: {voice}...")
        final_timeline = AudioSegment.silent(duration=0)
        cursor_ms = 0
        
        for item in [x for x in translated_data if x is not None]:
            idx = item['idx']
            raw_p = work_dir / f"raw_{idx}.wav"
            fin_p = work_dir / f"fin_{idx}.wav"
            
            if tts_engine.synthesize(item['text'], raw_p):
                AudioTools.high_quality_stretch(raw_p, item['duration']*1000, fin_p)
                chunk = AudioSegment.from_file(fin_p if fin_p.exists() else raw_p)
            else:
                chunk = AudioSegment.silent(duration=int(item['duration']*1000))
            
            gap = int(item['start']*1000) - cursor_ms
            if gap > 0: final_timeline += AudioSegment.silent(duration=gap)
            final_timeline += chunk
            cursor_ms = int(item['start']*1000) + len(chunk)

        # 5. Mux
        out = PROCESSED_DIR / f"{video_path.stem}_{voice}.mp4"
        # Mutăm pista audio finală în processed/ pentru a fi servită prin /download
        dub = PROCESSED_DIR / f"{video_path.stem}_{voice}_dub.wav"
        final_timeline.export(dub, format="wav")
        
        subprocess.run([
            "ffmpeg", "-y", "-i", str(video_path), "-i", str(dub),
            "-map", "0:v:0", "-map", "1:a:0", "-c:v", "copy", "-c:a", "aac",
            "-shortest", str(out)
        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        print(f"[DONE] Video salvat: {out}")
        return {
            "video_file": f"/download/{out.name}",
            "subtitle_file": "",
            "summary_file": "",
            "summary_text": "",
            "audio_file": f"/download/{dub.name}",
            "detected_language": detected_lang,
            "processed_dir": str(PROCESSED_DIR),
        }

    def redub(self, video_path: str, dest_lang: str = "ro", speaker_wav: str = None, translator_mode: str = "cloud"):
        """Alias compatibil cu app.py; voice cloning nu este folosit în această implementare."""
        return self.run(video_path, dest_lang=dest_lang, translator_mode=translator_mode)

if _name_ == "_main_":
    redubber = VideoRedubber()
    
    # Exemplu 1: Cu voce feminină (Default)
    redubber.run("input.mp4", voice="doru")
    
    # Exemplu 2: Cu voce masculină
    # redubber.run("input.mp4", voice="doru")
        return jsonify({'error': str(e)}), 500
